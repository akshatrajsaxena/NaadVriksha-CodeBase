{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07a5bf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from best_model.h5\n",
      "Model input shape: (None, 20, 9)\n",
      "Model output shape: (None, 4)\n",
      "============================================================\n",
      "REAL-TIME SENSOR-TO-MUSIC CONVERSION SYSTEM\n",
      "============================================================\n",
      "Loaded sensor data: (2273, 10)\n",
      "Columns: ['16:43:43', '0.849264705882353', '0.1866666666666666', '0.034313725490196', '0.5076142131979695', '0.1735159817351598', '0.4686246810061975', '0.480494966442953', '0.3984025793214626', '0.0909090909090909']\n",
      "Required feature columns not found in CSV\n",
      "Failed to load sensor data. Exiting.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 610\u001b[0m\n\u001b[0;32m    607\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- generation_report.txt (Summary report)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    609\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 610\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 597\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    590\u001b[0m system \u001b[38;5;241m=\u001b[39m RealTimeMusicSystem(\n\u001b[0;32m    591\u001b[0m     model_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    592\u001b[0m     sequence_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m    593\u001b[0m     feature_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m\n\u001b[0;32m    594\u001b[0m )\n\u001b[0;32m    596\u001b[0m \u001b[38;5;66;03m# Run the complete pipeline\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m midi_file, audio_file \u001b[38;5;241m=\u001b[39m system\u001b[38;5;241m.\u001b[39mrun_complete_pipeline(\n\u001b[0;32m    598\u001b[0m     sensor_data_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmidiMusic.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    599\u001b[0m     simulation_delay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.02\u001b[39m  \u001b[38;5;66;03m# Fast simulation for demonstration\u001b[39;00m\n\u001b[0;32m    600\u001b[0m )\n\u001b[0;32m    602\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSystem ready for real-time operation!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFiles generated in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMIDI\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m directory:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import threading\n",
    "from collections import deque\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning and Model Loading\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "# MIDI and Audio Libraries\n",
    "import pretty_midi\n",
    "import mido\n",
    "import pygame\n",
    "from scipy.io import wavfile\n",
    "import soundfile as sf\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "class CustomAttention(Layer):\n",
    "    \"\"\"Custom attention mechanism as a proper Keras layer\"\"\"\n",
    "    \n",
    "    def __init__(self, attention_dim=64, **kwargs):\n",
    "        super(CustomAttention, self).__init__(**kwargs)\n",
    "        self.attention_dim = attention_dim\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.input_dim = input_shape[-1]\n",
    "        self.query_dense = tf.keras.layers.Dense(self.attention_dim, activation='tanh')\n",
    "        self.key_dense = tf.keras.layers.Dense(self.attention_dim, activation='tanh')\n",
    "        self.value_dense = tf.keras.layers.Dense(self.input_dim, activation='tanh')\n",
    "        super(CustomAttention, self).build(input_shape)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        query = self.query_dense(inputs)\n",
    "        key = self.key_dense(inputs)\n",
    "        value = self.value_dense(inputs)\n",
    "        \n",
    "        attention_scores = tf.keras.backend.batch_dot(query, key, axes=[2, 2])\n",
    "        attention_scores = tf.nn.softmax(attention_scores, axis=-1)\n",
    "        \n",
    "        attended = tf.keras.backend.batch_dot(attention_scores, value, axes=[2, 1])\n",
    "        attended = attended + inputs\n",
    "        \n",
    "        return attended\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(CustomAttention, self).get_config()\n",
    "        config.update({\"attention_dim\": self.attention_dim})\n",
    "        return config\n",
    "\n",
    "class SensorDataBuffer:\n",
    "    \"\"\"Manages sliding window of sensor data\"\"\"\n",
    "    \n",
    "    def __init__(self, sequence_length=20, feature_dim=9):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.feature_dim = feature_dim\n",
    "        self.buffer = deque(maxlen=sequence_length)\n",
    "        self.feature_means = None\n",
    "        self.feature_stds = None\n",
    "        \n",
    "    def add_data_point(self, data_point):\n",
    "        \"\"\"Add new data point to buffer\"\"\"\n",
    "        if len(data_point) != self.feature_dim:\n",
    "            raise ValueError(f\"Data point must have {self.feature_dim} features\")\n",
    "        self.buffer.append(data_point)\n",
    "        \n",
    "    def get_sequence(self):\n",
    "        \"\"\"Get current sequence for model inference\"\"\"\n",
    "        if len(self.buffer) < self.sequence_length:\n",
    "            # Pad with zeros if not enough data\n",
    "            padded_data = np.zeros((self.sequence_length, self.feature_dim))\n",
    "            available_data = np.array(list(self.buffer))\n",
    "            padded_data[-len(available_data):] = available_data\n",
    "            return padded_data\n",
    "        else:\n",
    "            return np.array(list(self.buffer))\n",
    "    \n",
    "    def normalize_sequence(self, sequence):\n",
    "        \"\"\"Normalize sequence similar to training data\"\"\"\n",
    "        if self.feature_means is None or self.feature_stds is None:\n",
    "            # Initialize normalization parameters\n",
    "            self.feature_means = np.mean(sequence, axis=0)\n",
    "            self.feature_stds = np.std(sequence, axis=0) + 1e-8\n",
    "        \n",
    "        normalized = (sequence - self.feature_means) / self.feature_stds\n",
    "        return normalized\n",
    "    \n",
    "    def is_ready(self):\n",
    "        \"\"\"Check if buffer has enough data for inference\"\"\"\n",
    "        return len(self.buffer) >= self.sequence_length\n",
    "\n",
    "class WeatherToMusicMapper:\n",
    "    \"\"\"Maps weather predictions to musical parameters\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.weather_classes = ['Sunny', 'Rainy', 'Stormy', 'Windy']\n",
    "        \n",
    "        # Musical mapping dictionary\n",
    "        self.music_mapping = {\n",
    "            'Sunny': {\n",
    "                'key': 'C',\n",
    "                'scale': 'major',\n",
    "                'tempo': 120,\n",
    "                'instrument': 1,  # Piano\n",
    "                'chord_type': 'major',\n",
    "                'base_note': 60,  # C4\n",
    "                'velocity': 80,\n",
    "                'rhythm_pattern': [1, 0, 0.5, 0, 1, 0, 0.5, 0],\n",
    "                'chord_progression': [60, 64, 67, 72],  # C, E, G, C\n",
    "                'color': 'bright'\n",
    "            },\n",
    "            'Rainy': {\n",
    "                'key': 'Dm',\n",
    "                'scale': 'minor',\n",
    "                'tempo': 90,\n",
    "                'instrument': 48,  # String ensemble\n",
    "                'chord_type': 'minor',\n",
    "                'base_note': 62,  # D4\n",
    "                'velocity': 60,\n",
    "                'rhythm_pattern': [1, 0, 0, 0, 0.5, 0, 0, 0],\n",
    "                'chord_progression': [62, 65, 69, 74],  # D, F, A, D\n",
    "                'color': 'melancholic'\n",
    "            },\n",
    "            'Stormy': {\n",
    "                'key': 'G',\n",
    "                'scale': 'diminished',\n",
    "                'tempo': 140,\n",
    "                'instrument': 32,  # Distortion Guitar\n",
    "                'chord_type': 'diminished',\n",
    "                'base_note': 55,  # G3\n",
    "                'velocity': 100,\n",
    "                'rhythm_pattern': [1, 0.5, 1, 0.5, 1, 0.5, 1, 0.5],\n",
    "                'chord_progression': [55, 58, 61, 64],  # G, Bb, Db, E\n",
    "                'color': 'dramatic'\n",
    "            },\n",
    "            'Windy': {\n",
    "                'key': 'Am',\n",
    "                'scale': 'aeolian',\n",
    "                'tempo': 110,\n",
    "                'instrument': 73,  # Flute\n",
    "                'chord_type': 'minor',\n",
    "                'base_note': 57,  # A3\n",
    "                'velocity': 70,\n",
    "                'rhythm_pattern': [0.5, 0.5, 1, 0, 0.5, 0.5, 1, 0],\n",
    "                'chord_progression': [57, 60, 64, 67],  # A, C, E, G\n",
    "                'color': 'airy'\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def get_musical_parameters(self, prediction_class, confidence=1.0):\n",
    "        \"\"\"Get musical parameters for a weather prediction\"\"\"\n",
    "        if prediction_class >= len(self.weather_classes):\n",
    "            prediction_class = 0\n",
    "        \n",
    "        weather = self.weather_classes[prediction_class]\n",
    "        params = self.music_mapping[weather].copy()\n",
    "        \n",
    "        # Modify parameters based on confidence\n",
    "        params['velocity'] = int(params['velocity'] * confidence)\n",
    "        params['tempo'] = int(params['tempo'] * (0.8 + 0.4 * confidence))\n",
    "        \n",
    "        return params, weather\n",
    "\n",
    "class MIDIGenerator:\n",
    "    \"\"\"Generates and manages MIDI output\"\"\"\n",
    "    \n",
    "    def __init__(self, output_dir=\"MIDI\"):\n",
    "        self.output_dir = output_dir\n",
    "        self.ensure_output_dir()\n",
    "        \n",
    "        # Initialize MIDI\n",
    "        self.midi_file = pretty_midi.PrettyMIDI()\n",
    "        self.current_time = 0\n",
    "        self.note_duration = 0.5\n",
    "        \n",
    "        # Track different instruments\n",
    "        self.instruments = {}\n",
    "        \n",
    "        # For smoothing transitions\n",
    "        self.last_prediction = None\n",
    "        self.prediction_history = deque(maxlen=5)\n",
    "        \n",
    "    def ensure_output_dir(self):\n",
    "        \"\"\"Create output directory if it doesn't exist\"\"\"\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "            print(f\"Created output directory: {self.output_dir}\")\n",
    "    \n",
    "    def get_or_create_instrument(self, program, name):\n",
    "        \"\"\"Get or create instrument for MIDI\"\"\"\n",
    "        if name not in self.instruments:\n",
    "            instrument = pretty_midi.Instrument(program=program, name=name)\n",
    "            self.instruments[name] = instrument\n",
    "            self.midi_file.instruments.append(instrument)\n",
    "        return self.instruments[name]\n",
    "    \n",
    "    def smooth_prediction(self, new_prediction):\n",
    "        \"\"\"Smooth predictions to avoid abrupt changes\"\"\"\n",
    "        self.prediction_history.append(new_prediction)\n",
    "        \n",
    "        if len(self.prediction_history) < 3:\n",
    "            return new_prediction\n",
    "        \n",
    "        # Use majority voting for smoothing\n",
    "        recent_predictions = list(self.prediction_history)[-3:]\n",
    "        prediction_counts = {}\n",
    "        \n",
    "        for pred in recent_predictions:\n",
    "            prediction_counts[pred] = prediction_counts.get(pred, 0) + 1\n",
    "        \n",
    "        # Return most common prediction\n",
    "        smoothed_prediction = max(prediction_counts, key=prediction_counts.get)\n",
    "        return smoothed_prediction\n",
    "    \n",
    "    def generate_chord(self, base_note, chord_type, velocity=80):\n",
    "        \"\"\"Generate chord based on base note and type\"\"\"\n",
    "        if chord_type == 'major':\n",
    "            intervals = [0, 4, 7]\n",
    "        elif chord_type == 'minor':\n",
    "            intervals = [0, 3, 7]\n",
    "        elif chord_type == 'diminished':\n",
    "            intervals = [0, 3, 6]\n",
    "        else:\n",
    "            intervals = [0, 4, 7]  # Default to major\n",
    "        \n",
    "        chord_notes = [base_note + interval for interval in intervals]\n",
    "        return chord_notes\n",
    "    \n",
    "    def add_musical_phrase(self, params, weather_name, transition_smooth=True):\n",
    "        \"\"\"Add musical phrase to MIDI\"\"\"\n",
    "        # Get or create instrument\n",
    "        instrument = self.get_or_create_instrument(\n",
    "            params['instrument'], \n",
    "            f\"{weather_name}_instrument\"\n",
    "        )\n",
    "        \n",
    "        # Generate chord\n",
    "        chord_notes = self.generate_chord(\n",
    "            params['base_note'], \n",
    "            params['chord_type'], \n",
    "            params['velocity']\n",
    "        )\n",
    "        \n",
    "        # Add chord notes\n",
    "        for note_pitch in chord_notes:\n",
    "            note = pretty_midi.Note(\n",
    "                velocity=params['velocity'],\n",
    "                pitch=note_pitch,\n",
    "                start=self.current_time,\n",
    "                end=self.current_time + self.note_duration\n",
    "            )\n",
    "            instrument.notes.append(note)\n",
    "        \n",
    "        # Add melody note\n",
    "        melody_note = pretty_midi.Note(\n",
    "            velocity=params['velocity'] + 20,\n",
    "            pitch=params['base_note'] + 12,  # Octave higher\n",
    "            start=self.current_time,\n",
    "            end=self.current_time + self.note_duration\n",
    "        )\n",
    "        instrument.notes.append(melody_note)\n",
    "        \n",
    "        # Update time\n",
    "        beat_duration = 60.0 / params['tempo']\n",
    "        self.current_time += beat_duration\n",
    "    \n",
    "    def save_midi_file(self, filename=\"sensor_music.mid\"):\n",
    "        \"\"\"Save MIDI file\"\"\"\n",
    "        filepath = os.path.join(self.output_dir, filename)\n",
    "        self.midi_file.write(filepath)\n",
    "        print(f\"MIDI file saved: {filepath}\")\n",
    "        return filepath\n",
    "    \n",
    "    def convert_to_audio(self, midi_filepath, audio_filename=\"sensor_music.wav\"):\n",
    "        \"\"\"Convert MIDI to audio using synthesizer\"\"\"\n",
    "        try:\n",
    "            # Load MIDI file\n",
    "            midi_data = pretty_midi.PrettyMIDI(midi_filepath)\n",
    "            \n",
    "            # Synthesize audio\n",
    "            audio = midi_data.synthesize(fs=44100)\n",
    "            \n",
    "            # Save as WAV\n",
    "            audio_filepath = os.path.join(self.output_dir, audio_filename)\n",
    "            sf.write(audio_filepath, audio, 44100)\n",
    "            print(f\"Audio file saved: {audio_filepath}\")\n",
    "            \n",
    "            return audio_filepath\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error converting MIDI to audio: {e}\")\n",
    "            return None\n",
    "\n",
    "class RealTimeMusicSystem:\n",
    "    \"\"\"Main system orchestrating sensor data to music conversion\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path=\"best_model.h5\", sequence_length=20, feature_dim=9):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.feature_dim = feature_dim\n",
    "        \n",
    "        # Initialize components\n",
    "        self.data_buffer = SensorDataBuffer(sequence_length, feature_dim)\n",
    "        self.music_mapper = WeatherToMusicMapper()\n",
    "        self.midi_generator = MIDIGenerator()\n",
    "        \n",
    "        # Load model\n",
    "        self.model = self.load_model(model_path)\n",
    "        \n",
    "        # System state\n",
    "        self.is_running = False\n",
    "        self.prediction_count = 0\n",
    "        self.current_weather = None\n",
    "        \n",
    "        # Performance metrics\n",
    "        self.inference_times = []\n",
    "        self.predictions_history = []\n",
    "        \n",
    "    def load_model(self, model_path):\n",
    "        \"\"\"Load the pre-trained model\"\"\"\n",
    "        try:\n",
    "            # Register custom objects\n",
    "            custom_objects = {'CustomAttention': CustomAttention}\n",
    "            model = load_model(model_path, custom_objects=custom_objects)\n",
    "            print(f\"Model loaded successfully from {model_path}\")\n",
    "            print(f\"Model input shape: {model.input_shape}\")\n",
    "            print(f\"Model output shape: {model.output_shape}\")\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def load_sensor_data(self, filepath=\"midiMusic.csv\"):\n",
    "        \"\"\"Load sensor data from CSV file\"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(filepath)\n",
    "            print(f\"Loaded sensor data: {df.shape}\")\n",
    "            print(f\"Columns: {df.columns.tolist()}\")\n",
    "            \n",
    "            # Extract feature columns\n",
    "            feature_cols = ['Timestamp','Temperature', 'Humidity', 'Acc_X', 'Acc_Y', 'Acc_Z', \n",
    "                           'Gyro_X', 'Gyro_Y', 'Gyro_Z', 'LDR']\n",
    "            \n",
    "            if all(col in df.columns for col in feature_cols):\n",
    "                sensor_data = df[feature_cols].values\n",
    "                print(f\"Extracted {len(sensor_data)} sensor readings\")\n",
    "                return sensor_data\n",
    "            else:\n",
    "                print(\"Required feature columns not found in CSV\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading sensor data: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def predict_weather(self, sensor_sequence):\n",
    "        \"\"\"Make weather prediction from sensor sequence\"\"\"\n",
    "        if self.model is None:\n",
    "            return None, None\n",
    "        \n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Normalize sequence\n",
    "            normalized_sequence = self.data_buffer.normalize_sequence(sensor_sequence)\n",
    "            \n",
    "            # Reshape for model input\n",
    "            input_data = normalized_sequence.reshape(1, self.sequence_length, self.feature_dim)\n",
    "            \n",
    "            # Make prediction\n",
    "            prediction_probs = self.model.predict(input_data, verbose=0)\n",
    "            predicted_class = np.argmax(prediction_probs[0])\n",
    "            confidence = np.max(prediction_probs[0])\n",
    "            \n",
    "            # Record inference time\n",
    "            inference_time = time.time() - start_time\n",
    "            self.inference_times.append(inference_time)\n",
    "            \n",
    "            return predicted_class, confidence\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in weather prediction: {e}\")\n",
    "            return None, None\n",
    "    \n",
    "    def process_sensor_data_point(self, data_point):\n",
    "        \"\"\"Process single sensor data point\"\"\"\n",
    "        # Add to buffer\n",
    "        self.data_buffer.add_data_point(data_point)\n",
    "        \n",
    "        # Check if ready for inference\n",
    "        if not self.data_buffer.is_ready():\n",
    "            return None\n",
    "        \n",
    "        # Get sequence and make prediction\n",
    "        sequence = self.data_buffer.get_sequence()\n",
    "        predicted_class, confidence = self.predict_weather(sequence)\n",
    "        \n",
    "        if predicted_class is not None:\n",
    "            # Smooth prediction\n",
    "            smoothed_prediction = self.midi_generator.smooth_prediction(predicted_class)\n",
    "            \n",
    "            # Get musical parameters\n",
    "            params, weather_name = self.music_mapper.get_musical_parameters(\n",
    "                smoothed_prediction, confidence\n",
    "            )\n",
    "            \n",
    "            # Generate music\n",
    "            self.midi_generator.add_musical_phrase(params, weather_name)\n",
    "            \n",
    "            # Update state\n",
    "            self.current_weather = weather_name\n",
    "            self.prediction_count += 1\n",
    "            self.predictions_history.append((weather_name, confidence))\n",
    "            \n",
    "            return {\n",
    "                'weather': weather_name,\n",
    "                'confidence': confidence,\n",
    "                'prediction_count': self.prediction_count,\n",
    "                'musical_params': params\n",
    "            }\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def simulate_real_time_stream(self, sensor_data, delay=0.1):\n",
    "        \"\"\"Simulate real-time sensor data stream\"\"\"\n",
    "        print(f\"Starting real-time simulation with {len(sensor_data)} data points\")\n",
    "        print(f\"Delay between readings: {delay} seconds\")\n",
    "        \n",
    "        self.is_running = True\n",
    "        \n",
    "        for i, data_point in enumerate(sensor_data):\n",
    "            if not self.is_running:\n",
    "                break\n",
    "            \n",
    "            # Process data point\n",
    "            result = self.process_sensor_data_point(data_point)\n",
    "            \n",
    "            if result:\n",
    "                print(f\"Step {i+1}: {result['weather']} \"\n",
    "                      f\"(confidence: {result['confidence']:.3f}, \"\n",
    "                      f\"tempo: {result['musical_params']['tempo']})\")\n",
    "            \n",
    "            # Wait before next reading\n",
    "            time.sleep(delay)\n",
    "        \n",
    "        print(\"Real-time simulation completed\")\n",
    "    \n",
    "    def generate_music_visualization(self):\n",
    "        \"\"\"Generate visualization of music generation process\"\"\"\n",
    "        if not self.predictions_history:\n",
    "            print(\"No predictions to visualize\")\n",
    "            return\n",
    "        \n",
    "        # Create visualization\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # Weather predictions over time\n",
    "        weather_names = [pred[0] for pred in self.predictions_history]\n",
    "        confidences = [pred[1] for pred in self.predictions_history]\n",
    "        \n",
    "        # Plot weather timeline\n",
    "        axes[0, 0].plot(weather_names, 'o-', markersize=6)\n",
    "        axes[0, 0].set_title('Weather Predictions Timeline')\n",
    "        axes[0, 0].set_xlabel('Time Steps')\n",
    "        axes[0, 0].set_ylabel('Weather Class')\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot confidence levels\n",
    "        axes[0, 1].plot(confidences, 'g-', linewidth=2)\n",
    "        axes[0, 1].set_title('Prediction Confidence Over Time')\n",
    "        axes[0, 1].set_xlabel('Time Steps')\n",
    "        axes[0, 1].set_ylabel('Confidence')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Weather distribution\n",
    "        weather_counts = {}\n",
    "        for weather in weather_names:\n",
    "            weather_counts[weather] = weather_counts.get(weather, 0) + 1\n",
    "        \n",
    "        axes[1, 0].bar(weather_counts.keys(), weather_counts.values())\n",
    "        axes[1, 0].set_title('Weather Class Distribution')\n",
    "        axes[1, 0].set_xlabel('Weather Class')\n",
    "        axes[1, 0].set_ylabel('Count')\n",
    "        \n",
    "        # Inference time performance\n",
    "        if self.inference_times:\n",
    "            axes[1, 1].plot(self.inference_times, 'r-', alpha=0.7)\n",
    "            axes[1, 1].set_title('Model Inference Time')\n",
    "            axes[1, 1].set_xlabel('Prediction Number')\n",
    "            axes[1, 1].set_ylabel('Time (seconds)')\n",
    "            axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(self.midi_generator.output_dir, 'music_generation_analysis.png'))\n",
    "        plt.show()\n",
    "    \n",
    "    def generate_final_music_file(self):\n",
    "        \"\"\"Generate final music files\"\"\"\n",
    "        print(\"\\nGenerating final music files...\")\n",
    "        \n",
    "        # Save MIDI file\n",
    "        midi_filepath = self.midi_generator.save_midi_file(\"sensor_generated_music.mid\")\n",
    "        \n",
    "        # Convert to audio\n",
    "        audio_filepath = self.midi_generator.convert_to_audio(\n",
    "            midi_filepath, \n",
    "            \"sensor_generated_music.wav\"\n",
    "        )\n",
    "        \n",
    "        # Generate summary report\n",
    "        self.generate_summary_report()\n",
    "        \n",
    "        return midi_filepath, audio_filepath\n",
    "    \n",
    "    def generate_summary_report(self):\n",
    "        \"\"\"Generate summary report of the music generation process\"\"\"\n",
    "        report_filepath = os.path.join(self.midi_generator.output_dir, \"generation_report.txt\")\n",
    "        \n",
    "        with open(report_filepath, 'w') as f:\n",
    "            f.write(\"SENSOR-TO-MUSIC GENERATION REPORT\\n\")\n",
    "            f.write(\"=\"*50 + \"\\n\\n\")\n",
    "            \n",
    "            f.write(f\"Total predictions made: {self.prediction_count}\\n\")\n",
    "            f.write(f\"Total music duration: {self.midi_generator.current_time:.2f} seconds\\n\\n\")\n",
    "            \n",
    "            if self.predictions_history:\n",
    "                f.write(\"WEATHER PREDICTIONS SUMMARY:\\n\")\n",
    "                weather_counts = {}\n",
    "                for weather, _ in self.predictions_history:\n",
    "                    weather_counts[weather] = weather_counts.get(weather, 0) + 1\n",
    "                \n",
    "                for weather, count in weather_counts.items():\n",
    "                    percentage = (count / len(self.predictions_history)) * 100\n",
    "                    f.write(f\"  {weather}: {count} ({percentage:.1f}%)\\n\")\n",
    "            \n",
    "            f.write(f\"\\nAverage inference time: {np.mean(self.inference_times):.4f} seconds\\n\")\n",
    "            f.write(f\"Musical instruments used: {len(self.midi_generator.instruments)}\\n\")\n",
    "            \n",
    "            f.write(\"\\nINSTRUMENT MAPPING:\\n\")\n",
    "            for weather, params in self.music_mapper.music_mapping.items():\n",
    "                f.write(f\"  {weather}: Instrument {params['instrument']}, \"\n",
    "                       f\"Key {params['key']}, Tempo {params['tempo']}\\n\")\n",
    "        \n",
    "        print(f\"Summary report saved: {report_filepath}\")\n",
    "    \n",
    "    def run_complete_pipeline(self, sensor_data_file=\"midiMusic.csv\", simulation_delay=0.05):\n",
    "        \"\"\"Run the complete sensor-to-music pipeline\"\"\"\n",
    "        print(\"=\"*60)\n",
    "        print(\"REAL-TIME SENSOR-TO-MUSIC CONVERSION SYSTEM\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Load sensor data\n",
    "        sensor_data = self.load_sensor_data(sensor_data_file)\n",
    "        if sensor_data is None:\n",
    "            print(\"Failed to load sensor data. Exiting.\")\n",
    "            return\n",
    "        \n",
    "        # Simulate real-time processing\n",
    "        self.simulate_real_time_stream(sensor_data, delay=simulation_delay)\n",
    "        \n",
    "        # Generate visualizations\n",
    "        self.generate_music_visualization()\n",
    "        \n",
    "        # Generate final music files\n",
    "        midi_file, audio_file = self.generate_final_music_file()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"MIDI file: {midi_file}\")\n",
    "        print(f\"Audio file: {audio_file}\")\n",
    "        print(f\"Total predictions: {self.prediction_count}\")\n",
    "        print(f\"Music duration: {self.midi_generator.current_time:.2f} seconds\")\n",
    "        \n",
    "        return midi_file, audio_file\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    # Initialize the system\n",
    "    system = RealTimeMusicSystem(\n",
    "        model_path=\"best_model.h5\",\n",
    "        sequence_length=20,\n",
    "        feature_dim=9\n",
    "    )\n",
    "    \n",
    "    # Run the complete pipeline\n",
    "    midi_file, audio_file = system.run_complete_pipeline(\n",
    "        sensor_data_file=\"midiMusic.csv\",\n",
    "        simulation_delay=0.02  # Fast simulation for demonstration\n",
    "    )\n",
    "    \n",
    "    print(\"\\nSystem ready for real-time operation!\")\n",
    "    print(\"Files generated in 'MIDI' directory:\")\n",
    "    print(\"- sensor_generated_music.mid (MIDI file)\")\n",
    "    print(\"- sensor_generated_music.wav (Audio file)\")\n",
    "    print(\"- music_generation_analysis.png (Visualization)\")\n",
    "    print(\"- generation_report.txt (Summary report)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
