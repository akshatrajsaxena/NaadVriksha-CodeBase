{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a5bf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Layer\n",
    "import mido\n",
    "import pretty_midi\n",
    "import time\n",
    "import threading\n",
    "import queue\n",
    "import os\n",
    "from collections import deque\n",
    "import random\n",
    "import soundfile as sf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class CustomAttention(Layer):    \n",
    "    def __init__(self, attention_dim=64, **kwargs):\n",
    "        super(CustomAttention, self).__init__(**kwargs)\n",
    "        self.attention_dim = attention_dim\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.input_dim = input_shape[-1]\n",
    "        self.query_dense = tf.keras.layers.Dense(self.attention_dim, activation='tanh')\n",
    "        self.key_dense = tf.keras.layers.Dense(self.attention_dim, activation='tanh')\n",
    "        self.value_dense = tf.keras.layers.Dense(self.input_dim, activation='tanh')\n",
    "        super(CustomAttention, self).build(input_shape)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        query = self.query_dense(inputs)\n",
    "        key = self.key_dense(inputs)\n",
    "        value = self.value_dense(inputs)\n",
    "        attention_scores = tf.keras.backend.batch_dot(query, key, axes=[2, 2])\n",
    "        attention_scores = tf.nn.softmax(attention_scores, axis=-1)\n",
    "        attended = tf.keras.backend.batch_dot(attention_scores, value, axes=[2, 1])\n",
    "        attended = attended + inputs\n",
    "        \n",
    "        return attended\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(CustomAttention, self).get_config()\n",
    "        config.update({\"attention_dim\": self.attention_dim})\n",
    "        return config\n",
    "\n",
    "class SensorToMIDISystem:\n",
    "    def __init__(self, model_path=\"best_model.h5\", data_path=\"midiMusic.csv\", output_dir=\"MIDI\", sequence_length=20, feature_dim=9):\n",
    "        self.model_path = model_path\n",
    "        self.data_path = data_path\n",
    "        self.output_dir = output_dir\n",
    "        self.sequence_length = sequence_length\n",
    "        self.feature_dim = feature_dim\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "        self.model = None\n",
    "        self.data_buffer = deque(maxlen=sequence_length)\n",
    "        self.sensor_data = None\n",
    "        self.current_index = 0\n",
    "        self.running = False\n",
    "        self.current_class = None\n",
    "        self.previous_class = None\n",
    "        self.class_stability_counter = 0\n",
    "        self.min_stability_frames = 3\n",
    "        self.midi_data = pretty_midi.PrettyMIDI()\n",
    "        self.current_time = 0.0\n",
    "        self.tempo = 120  \n",
    "        self.active_notes = []\n",
    "        self.load_model()\n",
    "        self.load_sensor_data()\n",
    "        self.initialize_music_mapping()\n",
    "        \n",
    "    def load_model(self):\n",
    "        print(\"Loading pre-trained model...\")\n",
    "        try:\n",
    "            custom_objects = {'CustomAttention': CustomAttention}\n",
    "            self.model = load_model(self.model_path, custom_objects=custom_objects)\n",
    "            print(\"Model loaded successfully!\")\n",
    "            self.model.summary()\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def load_sensor_data(self):\n",
    "        print(\"Loading sensor data...\")\n",
    "        try:\n",
    "            self.sensor_data = pd.read_csv(self.data_path)\n",
    "            print(f\"Loaded {len(self.sensor_data)} data points\")\n",
    "            self.feature_cols = ['Temperature', 'Humidity', 'Acc_X', 'Acc_Y', 'Acc_Z','Gyro_X', 'Gyro_Y', 'Gyro_Z', 'LDR']\n",
    "            self.features = self.sensor_data[self.feature_cols].values\n",
    "            print(f\"Features shape: {self.features.shape}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading sensor data: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def initialize_music_mapping(self):\n",
    "        self.weather_classes = ['Sunny', 'Rainy', 'Stormy', 'Windy']\n",
    "        self.music_mapping = {\n",
    "            0: { 'name': 'Sunny', 'scale': [60, 62, 64, 65, 67, 69, 71], 'chord_type': 'major', 'base_note': 60, 'instrument': 1, 'tempo': 120, 'velocity': 80, 'rhythm_pattern': [1, 0, 1, 0, 1, 0, 1, 0], 'chord_progression': [60, 65, 67, 60], 'color': 'bright' }, 1: { 'name': 'Rainy', 'scale': [57, 59, 60, 62, 64, 65, 67], 'chord_type': 'minor', 'base_note': 57, 'instrument': 46, 'tempo': 90, 'velocity': 60, 'rhythm_pattern': [1, 0, 0, 1, 0, 1, 0, 0], 'chord_progression': [57, 60, 62, 57], 'color': 'melancholic' }, 2: { 'name': 'Stormy', 'scale': [62, 63, 66, 67, 70, 71, 74], 'chord_type': 'diminished', 'base_note': 38, 'instrument': 39, 'tempo': 140, 'velocity': 110, 'rhythm_pattern': [1, 1, 0, 1, 1, 0, 1, 1], 'chord_progression': [62, 67, 70, 62], 'color': 'dark' }, 3: { 'name': 'Windy', 'scale': [64, 66, 68, 69, 71, 73, 75], 'chord_type': 'major7', 'base_note': 64, 'instrument': 73, 'tempo': 110, 'velocity': 90, 'rhythm_pattern': [1, 0, 1, 1, 0, 1, 0, 1], 'chord_progression': [64, 69, 71, 64], 'color': 'airy' }\n",
    "        }\n",
    "    \n",
    "    def normalize_sequence(self, sequence):\n",
    "        sequence = np.array(sequence)\n",
    "        normalized = (sequence - np.mean(sequence, axis=0, keepdims=True)) / (np.std(sequence, axis=0, keepdims=True) + 1e-8)\n",
    "        return normalized\n",
    "    \n",
    "    def predict_weather_class(self, sensor_sequence):\n",
    "        if len(sensor_sequence) < self.sequence_length:\n",
    "            return None\n",
    "        input_data = np.array(sensor_sequence).reshape(1, self.sequence_length, self.feature_dim)\n",
    "        input_data = self.normalize_sequence(input_data)\n",
    "        prediction = self.model.predict(input_data, verbose=0)\n",
    "        predicted_class = np.argmax(prediction[0])\n",
    "        confidence = np.max(prediction[0])\n",
    "        \n",
    "        return predicted_class, confidence, prediction[0]\n",
    "    \n",
    "    def smooth_class_transition(self, new_class):\n",
    "        if self.current_class is None:\n",
    "            self.current_class = new_class\n",
    "            self.class_stability_counter = 0\n",
    "            return new_class\n",
    "        \n",
    "        if new_class == self.current_class:\n",
    "            self.class_stability_counter = min(self.class_stability_counter + 1, 10)\n",
    "            return self.current_class\n",
    "        else:\n",
    "            self.class_stability_counter -= 1\n",
    "            if self.class_stability_counter <= -self.min_stability_frames:\n",
    "                self.previous_class = self.current_class\n",
    "                self.current_class = new_class\n",
    "                self.class_stability_counter = 0\n",
    "                return new_class\n",
    "            else:\n",
    "                return self.current_class\n",
    "    \n",
    "    def generate_chord(self, weather_class, base_note=None):\n",
    "        mapping = self.music_mapping[weather_class]\n",
    "        if base_note is None:\n",
    "            base_note = mapping['base_note']\n",
    "        \n",
    "        chord_type = mapping['chord_type']\n",
    "        chord_notes = []\n",
    "        if chord_type == 'major':\n",
    "            chord_notes = [base_note, base_note + 4, base_note + 7]\n",
    "        elif chord_type == 'minor':\n",
    "            chord_notes = [base_note, base_note + 3, base_note + 7]\n",
    "        elif chord_type == 'diminished':\n",
    "            chord_notes = [base_note, base_note + 3, base_note + 6]\n",
    "        elif chord_type == 'major7':\n",
    "            chord_notes = [base_note, base_note + 4, base_note + 7, base_note + 11]\n",
    "        \n",
    "        return chord_notes\n",
    "    \n",
    "    def generate_melody_note(self, weather_class, step=0):\n",
    "        mapping = self.music_mapping[weather_class]\n",
    "        scale = mapping['scale']\n",
    "        rhythm = mapping['rhythm_pattern']\n",
    "        if rhythm[step % len(rhythm)] == 0:\n",
    "            return None\n",
    "        note_index = (step // 2) % len(scale)\n",
    "        if random.random() < 0.3:  \n",
    "            note_index = (note_index + random.choice([-1, 1])) % len(scale)\n",
    "        \n",
    "        return scale[note_index]\n",
    "    \n",
    "    def add_midi_note(self, note, velocity, start_time, duration, instrument=1):        \n",
    "        if len(self.midi_data.instruments) == 0 or self.midi_data.instruments[-1].program != instrument:\n",
    "            new_instrument = pretty_midi.Instrument(program=instrument)\n",
    "            self.midi_data.instruments.append(new_instrument)\n",
    "        \n",
    "        for instr in self.midi_data.instruments:\n",
    "            if instr.program == instrument:\n",
    "                midi_note = pretty_midi.Note(\n",
    "                    velocity=velocity,\n",
    "                    pitch=note,\n",
    "                    start=start_time,\n",
    "                    end=start_time + duration\n",
    "                )\n",
    "                instr.notes.append(midi_note)\n",
    "                break\n",
    "    \n",
    "    def process_sensor_data_step(self, step_index):\n",
    "        if step_index >= len(self.features):\n",
    "            return False\n",
    "        current_reading = self.features[step_index]\n",
    "        self.data_buffer.append(current_reading)\n",
    "        if len(self.data_buffer) == self.sequence_length:\n",
    "            result = self.predict_weather_class(list(self.data_buffer))\n",
    "            if result is not None:\n",
    "                predicted_class, confidence, probabilities = result\n",
    "                stable_class = self.smooth_class_transition(predicted_class)\n",
    "                self.generate_music_step(stable_class, step_index, confidence)\n",
    "                class_name = self.music_mapping[stable_class]['name']\n",
    "                print(f\"Step {step_index}: {class_name} (confidence: {confidence:.3f})\")\n",
    "                \n",
    "                return True\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def generate_music_step(self, weather_class, step_index, confidence):\n",
    "        mapping = self.music_mapping[weather_class]\n",
    "        beat_duration = 60.0 / mapping['tempo']  \n",
    "        note_duration = beat_duration * 0.8  \n",
    "        melody_note = self.generate_melody_note(weather_class, step_index)\n",
    "        \n",
    "        if melody_note is not None:\n",
    "            self.add_midi_note(\n",
    "                note=melody_note,velocity=int(mapping['velocity'] * confidence),start_time=self.current_time,duration=note_duration,instrument=mapping['instrument']\n",
    "            )\n",
    "        \n",
    "        if step_index % 4 == 0:  \n",
    "            chord_progression = mapping['chord_progression']\n",
    "            chord_root = chord_progression[(step_index // 4) % len(chord_progression)]\n",
    "            chord_notes = self.generate_chord(weather_class, chord_root)    \n",
    "            for chord_note in chord_notes:\n",
    "                self.add_midi_note(\n",
    "                    note=chord_note,\n",
    "                    velocity=int(mapping['velocity'] * 0.6),  \n",
    "                    start_time=self.current_time,\n",
    "                    duration=beat_duration * 2,  \n",
    "                    instrument=1  \n",
    "                )\n",
    "        if step_index % 8 == 0:  \n",
    "            bass_note = mapping['base_note'] - 12  \n",
    "            self.add_midi_note(\n",
    "                note=bass_note,\n",
    "                velocity=int(mapping['velocity'] * 0.8),\n",
    "                start_time=self.current_time,\n",
    "                duration=beat_duration * 4,  \n",
    "                instrument=33  \n",
    "            )\n",
    "        self.current_time += beat_duration / 2  \n",
    "    \n",
    "    def run_simulation(self, max_steps=None, step_delay=0.1):\n",
    "        print(\"Starting real-time sensor-to-MIDI simulation...\")\n",
    "        print(f\"Processing {len(self.features)} data points...\")\n",
    "        self.running = True\n",
    "        processed_steps = 0\n",
    "        try:\n",
    "            while self.running and self.current_index < len(self.features):\n",
    "                if max_steps and processed_steps >= max_steps:\n",
    "                    break\n",
    "                success = self.process_sensor_data_step(self.current_index)\n",
    "                if not success:\n",
    "                    break\n",
    "                self.current_index += 1\n",
    "                processed_steps += 1\n",
    "                time.sleep(step_delay)\n",
    "                if processed_steps % 50 == 0:\n",
    "                    print(f\"Processed {processed_steps} steps...\")\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Simulation interrupted by user\")\n",
    "        finally:\n",
    "            self.running = False\n",
    "            print(f\"Simulation completed. Processed {processed_steps} steps.\")\n",
    "    \n",
    "    def save_midi_file(self, filename=None):\n",
    "        if filename is None:\n",
    "            filename = os.path.join(self.output_dir, \"sensor_music.mid\")\n",
    "        tempo_changes = [pretty_midi.TempoChange(tempo=120, time=0)]\n",
    "        self.midi_data.tempo_changes = tempo_changes\n",
    "        self.midi_data.write(filename)\n",
    "        print(f\"MIDI file saved as: {filename}\")\n",
    "        return filename\n",
    "    \n",
    "    def midi_to_audio(self, midi_file, audio_file=None, sample_rate=44100):\n",
    "        if audio_file is None:\n",
    "            audio_file = os.path.join(self.output_dir, \"sensor_music.wav\")\n",
    "        try:\n",
    "            midi_data = pretty_midi.PrettyMIDI(midi_file)\n",
    "            audio = midi_data.synthesize(fs=sample_rate)\n",
    "            sf.write(audio_file, audio, sample_rate)\n",
    "            print(f\"Audio file saved as: {audio_file}\")\n",
    "            return audio_file\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error converting MIDI to audio: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def generate_summary_report(self):\n",
    "        report_file = os.path.join(self.output_dir, \"generation_report.txt\")\n",
    "        with open(report_file, 'w') as f:\n",
    "            f.write(\"Sensor-to-MIDI Music Generation Report\\n\")\n",
    "            f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "            f.write(f\"Total steps processed: {self.current_index}\\n\")\n",
    "            f.write(f\"Total music duration: {self.current_time:.2f} seconds\\n\\n\")\n",
    "            f.write(\"Weather Class Mapping:\\n\")\n",
    "            for class_id, mapping in self.music_mapping.items():\n",
    "                f.write(f\"  {class_id}: {mapping['name']}\\n\")\n",
    "                f.write(f\"    - Instrument: {mapping['instrument']}\\n\")\n",
    "                f.write(f\"    - Tempo: {mapping['tempo']} BPM\\n\")\n",
    "                f.write(f\"    - Base Note: {mapping['base_note']}\\n\")\n",
    "                f.write(f\"    - Chord Type: {mapping['chord_type']}\\n\\n\")\n",
    "            \n",
    "            f.write(\"Generated Files:\\n\")\n",
    "            f.write(\"  - sensor_music.mid (MIDI file)\\n\")\n",
    "            f.write(\"  - sensor_music.wav (Audio file)\\n\")\n",
    "            f.write(\"  - generation_report.txt (This report)\\n\")\n",
    "        \n",
    "        print(f\"Report saved as: {report_file}\")\n",
    "\n",
    "def main():\n",
    "    print(\"Initializing Sensor-to-MIDI Music System...\")\n",
    "    system = SensorToMIDISystem(\n",
    "        model_path=\"best_model.h5\",data_path=\"midiMusic.csv\",output_dir=\"MIDI\"\n",
    "    )\n",
    "    print(\"Starting music generation simulation...\")\n",
    "    system.run_simulation(max_steps=200, step_delay=0.05)\n",
    "    print(\"Saving generated music...\")\n",
    "    midi_file = system.save_midi_file()\n",
    "    audio_file = system.midi_to_audio(midi_file)\n",
    "    system.generate_summary_report()\n",
    "    print(\"\\nMusic generation completed!\")\n",
    "    print(f\"Files saved in '{system.output_dir}' directory:\")\n",
    "    print(\"  - sensor_music.mid (MIDI file)\")\n",
    "    print(\"  - sensor_music.wav (Audio file)\")\n",
    "    print(\"  - generation_report.txt (Generation report)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
